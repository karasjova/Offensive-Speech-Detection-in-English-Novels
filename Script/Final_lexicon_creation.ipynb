{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import nltk\nfrom nltk.stem import PorterStemmer\nfrom nltk.sentiment import SentimentIntensityAnalyzer\nfrom sentence_transformers import SentenceTransformer, util\nfrom textblob import TextBlob\nimport pandas as pd\nimport torch\nimport matplotlib.pyplot as plt\nfrom collections import Counter\n\nnltk.download('punkt')\nnltk.download('vader_lexicon')\n\n# ====================\n# Tokenization function\n# ====================\ndef tokenize_text(text: str, lower: bool = True, only_alpha: bool = True):\n\n    if lower:\n        text = text.lower()\n\n    tokens = nltk.word_tokenize(text)\n\n    if only_alpha:\n        tokens = [t for t in tokens if t.isalpha()]\n\n    freq_dict = Counter(tokens)\n\n    unique_tokens = list(freq_dict.keys())\n\n    return unique_tokens, freq_dict\n\n# ====================\n# Input files and parameters\n# ====================\nsalinger_book_path = \"/kaggle/input/salinger2/Salinger - The Catcher in the Rye -English.txt\"\nhurtlex_path = \"/kaggle/input/hurtkex-filtered/hurtlex_filtered.xlsx\"\nthreshold = 0.6\n\n# ====================\n# Load and tokenize text\n# ====================\nwith open(salinger_book_path, \"r\", encoding=\"utf-8\") as f:\n    text = f.read()\n\ntokens, freq_dict = tokenize_text(text)\n\nprint(f\"Unique tokens count: {len(tokens)}\")\n\n# ====================\n# Load HurtLex\n# ====================\nhurtlex_df = pd.read_excel(hurtlex_path)\nhurtlex_words = set(hurtlex_df[\"lemma\"].dropna().str.lower().unique())\nprint(f\"Unique Hurtlex words count: {len(hurtlex_words)}\")\nhurtlex_list = list(hurtlex_words)\n\n# ====================\n# Initialize models and tools\n# ====================\nstemmer = PorterStemmer()\nanalyzer = SentimentIntensityAnalyzer()\nmodel = SentenceTransformer('all-MiniLM-L6-v2')\n\n# ====================\n# Vectorization\n# ====================\ntext_embeddings = model.encode(tokens, convert_to_tensor=True)\nhurtlex_embeddings = model.encode(hurtlex_list, convert_to_tensor=True)\n\n# ====================\n# Search for new words\n# ====================\nresults = []\n\nfor i, token in enumerate(tokens):\n    token_emb = text_embeddings[i]\n    cosine_scores = util.cos_sim(token_emb, hurtlex_embeddings)[0]\n\n    max_score = float(cosine_scores.max())\n    matched_idx = int(torch.argmax(cosine_scores))\n    matched_word = hurtlex_list[matched_idx]\n\n    #Cosine similarity threshold\n    if max_score < threshold:\n        continue\n\n    #Skip exact matches with HurtLex\n    if token == matched_word:\n        continue\n\n    #VADER polarity\n    vader_compound = analyzer.polarity_scores(token)[\"compound\"]\n    vader_neg = vader_compound < 0\n\n    #TextBlob polarity\n    tb_polarity = TextBlob(token).sentiment.polarity\n    tb_neg = tb_polarity < 0\n\n    #Agreement level\n    level_of_agreement = int(vader_neg and tb_neg)\n\n    #Token type detection\n    if stemmer.stem(token) == stemmer.stem(matched_word):\n        token_type = \"extra_form\"\n    else:\n        token_type = \"new_lemma\"\n\n    #Save result \n    results.append({\n        \"token\": token,\n        \"matched_word\": matched_word,\n        \"similarity\": f\"{max_score:.4f}\",\n        \"vader_compound\": f\"{vader_compound:.4f}\",\n        \"textblob_polarity\": f\"{tb_polarity:.4f}\",\n        \"vader_neg\": vader_neg,\n        \"textblob_neg\": tb_neg,\n        \"level_of_agreement\": level_of_agreement,\n        \"type\": token_type\n    })\n# ====================\n# Save token comparison\n# ====================\ndf_results = pd.DataFrame(results)\ndf_results.to_csv(\"tokens_comparison_vader_textblob.csv\", index=False, encoding=\"utf-8\")\n\n# ====================\n# Collect negative tokens by VAder\n# ====================\nneg_tokens_set = set(df_results[df_results[\"vader_neg\"]][\"token\"].unique())\nprint(f\"Unique negative tokens count: {len(neg_tokens_set)}\")  # должно быть 114\n\n# ====================\n# Merge with HurtLex words\n# ====================\nall_words_set = neg_tokens_set.union(hurtlex_words)\nprint(f\"All words count: {len(all_words_set)}\") \n\ndf_all_words = pd.DataFrame({\"word\": list(all_words_set)})\ndf_all_words.to_csv(\"all_hurtlex_and_neg_vader_words.csv\", index=False, encoding=\"utf-8\")\n\n# ====================\n# Summary table\n# ====================\nsummary_table = pd.DataFrame({\n    \"Method\": [\"VADER\", \"TextBlob\", \"Agreement (both)\"],\n    \"Extra_forms\": [\n        df_results[df_results[\"vader_neg\"] & (df_results[\"type\"]==\"extra_form\")].shape[0],\n        df_results[df_results[\"textblob_neg\"] & (df_results[\"type\"]==\"extra_form\")].shape[0],\n        df_results[(df_results[\"level_of_agreement\"]==1) & (df_results[\"type\"]==\"extra_form\")].shape[0]\n    ],\n    \"New_lemmas\": [\n        df_results[df_results[\"vader_neg\"] & (df_results[\"type\"]==\"new_lemma\")].shape[0],\n        df_results[df_results[\"textblob_neg\"] & (df_results[\"type\"]==\"new_lemma\")].shape[0],\n        df_results[(df_results[\"level_of_agreement\"]==1) & (df_results[\"type\"]==\"new_lemma\")].shape[0]\n    ]\n})\nsummary_table[\"Total\"] = summary_table[\"Extra_forms\"] + summary_table[\"New_lemmas\"]\nprint(summary_table)\n\n# ====================\n# Plot comparison diagram\n# ====================\nlabels = [\"Extra forms\", \"New lemmas\"]\nvader_counts = [summary_table.loc[0, \"Extra_forms\"], summary_table.loc[0, \"New_lemmas\"]]\ntb_counts = [summary_table.loc[1, \"Extra_forms\"], summary_table.loc[1, \"New_lemmas\"]]\nagreement_counts = [summary_table.loc[2, \"Extra_forms\"], summary_table.loc[2, \"New_lemmas\"]]\n\nx = range(len(labels))\nwidth = 0.25\n\nplt.figure(figsize=(8,6))\nbars_vader = plt.bar([p - width for p in x], vader_counts, width=width, color='red', label='VADER')\nbars_tb = plt.bar(x, tb_counts, width=width, color='blue', label='TextBlob')\nbars_agree = plt.bar([p + width for p in x], agreement_counts, width=width, color='green', label='Agreement (both)')\n\ndef add_labels(bars):\n    for bar in bars:\n        height = bar.get_height()\n        plt.text(bar.get_x() + bar.get_width()/2, height + 0.5, str(height), ha='center', va='bottom', fontsize=10)\n\nadd_labels(bars_vader)\nadd_labels(bars_tb)\nadd_labels(bars_agree)\n\nplt.xticks(x, labels)\nplt.ylabel(\"Count of negative words\")\nplt.title(\"Comparison of negative words detection methods: VADER vs TextBlob\")\nplt.legend()\nplt.show()","metadata":{"_uuid":"717a5187-e58e-440c-bf2a-b1a4b085f752","_cell_guid":"a5aa72b1-ce11-4494-aee1-93398395b02f","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}
